{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Sample Wilcoxon Signed Rank Test\n",
    "*By P. Stikker*<br>\n",
    "https://PeterStatistics.com<br>\n",
    "https://www.youtube.com/stikpet<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two tests can be used to test a hypothesized median. The first does exactly what this and is known as a sign-test, however another test is more frequently used and has a lot scarier name: one-sample Wilcoxon signed rank test (Wilcoxon, 1945). This second test uses rankings (it ranks the scores) and because of this might give a slightly different result. The advantage of this second test is that it can catch some smaller differences and is the one I will explain here. If you are curious about what the Wilcoxon test does exactly I'd recommend <a href=\"https://onlinecourses.science.psu.edu/stat414/node/319\">this site</a>. \n",
    "\n",
    "In the Example section, I'll discuss how to perform a one-sample Wilcoxon Signed Rank Test with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need some example data. I'll import it as a Pandas dataframe, so will need 'pandas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       # https://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then load the example data using the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\">'read_csv'</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peter\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (11,115,123,187,274,284,287,288,290,291,292,397,585,595,628,632) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "myDf = pd.read_csv('../Data/csv/GSS2012a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myField = myDf['accntsci'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories in this field are their original labels, but need to be numeric values, so we should re-code the field into numeric values.\n",
    "\n",
    "Lets first see which options there were (using '<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\">unique</a>')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Very scientific', 'Pretty scientific', 'Not too scientific',\n",
       "       'Not scientific at all'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myField.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assign these to numeric values, by making a dictionary out of the coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCoding = {'Not scientific at all': 1, 'Not too scientific': 2, 'Pretty scientific': 3, 'Very scientific': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to replace the labels with their new codes (using '<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html\">replace</a>'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "myField2 = myField.replace(myCoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wilcoxon test can be found in the scipy.stats library. So lets import that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon  # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test requires a hypothesized median. I'd like to use the middle value of the possible scores for this, so in the example thats right between 'Not too scientific' and 'Pretty scientific', so at 2.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "medHyp = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the test, will look at the differences with this hypothesized median, so each time at 'myField2-medHyp', the test itself can then be done as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129626.0\n",
      "8.078555909697749e-33\n"
     ]
    }
   ],
   "source": [
    "rank, pVal = wilcoxon(myField2-medHyp, zero_method = 'wilcox', correction = False)\n",
    "print(rank)\n",
    "print(pVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'zero_method' is about how it should deal with ties. That is, if the score is equal to the hypothesized median. The options are:\n",
    "\n",
    "* 'pratt', which will include the zero values when determining the ranks, but removes the ranks of the zero values itself.\n",
    "* 'wilcox', which simply first removes them\n",
    "* 'zsplit', includes the zero values and splits the ranks over the positive and negative ones.\n",
    "\n",
    "The 'correction' is about the continuity correction.\n",
    "\n",
    "The 129626 is either the sum of the ranks that were positive, or the sum of the ranks that had a negative deviation, whichever is smaller.\n",
    "\n",
    "The last value is the p-value (sig. in SPSS terms). It is the probability of results as in the sample, or even more extreme, if the population median would indeed be 2.5. Usually if this value is below .05 we would conclude that this assumption about the population is not true, and report that there is a significant difference.\n",
    "\n",
    "For the reporting a so-called Z-value is often noted as well, but unfortunately not returned by the wilcoxon function. Guess we'll have to reverse-engineer that.\n",
    "\n",
    "We'll need the function from the 'norm' package of scipy.stats for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm   # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, simply use the found p-value to find the corresponding z-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.931822145966912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(pVal/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to automate things, so below a function that will do all the work. To automate on deciding the hypothesized mean, I would also need the mean function from python's statistics library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean    # https://docs.python.org/3/library/statistics.html#statistics.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for my own function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wilcoxon one-sample test\n",
    "\n",
    "def wilcoxonOS(myData, field, catCoding=None, hypMed = None):\n",
    "    myField = myData[field].dropna()   \n",
    "    \n",
    "    if catCoding != None:\n",
    "        myField = myField.replace(catCoding)\n",
    "    myFreq = myField.value_counts()\n",
    "    \n",
    "    myMed = hypMed\n",
    "    if hypMed == None:\n",
    "        myMed = (min(myFreq.index)+max(myFreq.index))/2\n",
    "    \n",
    "    rank, pVal = wilcoxon(myField-myMed, zero_method = 'wilcox', correction = False)\n",
    "    zVal = norm.ppf(pVal/2)\n",
    "    \n",
    "    return rank, pVal, zVal, myMed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129626.0, 8.078555909697749e-33, -11.931822145966912, 2.5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxonOS(myDf, 'accntsci', catCoding={'Not scientific at all': 1, 'Not too scientific': 2, 'Pretty scientific': 3, 'Very scientific': 4}, hypMed = 2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236.5, 0.005298523793092, -2.7883013105590395, 3.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDf = pd.read_csv('../Data/csv/StudentStatistics.csv')\n",
    "wilcoxonOS(myDf, 'Teach_Motivate', catCoding = {'Fully Disagree': 1, 'Disagree': 2, 'Neither disagree nor agree': 3, 'Agree': 4, 'Fully agree': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Wilcoxon, F. (1945). Individual comparisons by ranking methods. *Biometrics Bulletin, 1*(6), 80. doi:10.2307/3001968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
